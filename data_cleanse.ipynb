{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da60b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39322978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in original csv from my GitHub\n",
    "initDataDf = pd.read_csv(\"https://raw.githubusercontent.com/JordanVencel/DFProject/main/Tesla.csv\")\n",
    "# Filter out tweets that are not in english \n",
    "filterDf = initDataDf[['language','tweet']]\n",
    "filterDf = filterDf.where(filterDf['language'] == 'en')\n",
    "filterDf = filterDf[filterDf['language'].notna()]\n",
    "# Grab only tweet text data\n",
    "tweetDf = filterDf['tweet'].to_frame()\n",
    "tweetDf = tweetDf.reset_index(drop=True)\n",
    "# Filter out @s, hashtags, external links, and other irrelavant information using regex\n",
    "for row in tweetDf.iterrows():\n",
    "    index = row[0]\n",
    "    booty = re.sub(r\"([@#])\\w+\", \"\", row[1][0])\n",
    "    booty = re.sub(r\"(https)([^\\s]+)\", \"\", booty)\n",
    "    booty = re.sub(r\"(\\?)\", \"\", booty)\n",
    "    booty = re.sub(r\"(.com)\", \"\", booty)\n",
    "    booty = re.sub(r\"([^A-Za-z0-9'!?$\\\",.\\s]*)\", \"\", booty)\n",
    "    booty = re.sub(r\"(^[ \\t]+)\", \"\", booty)\n",
    "    tweetDf.iloc[index][0] = booty\n",
    "\n",
    "tweetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up row id formatting for nltk\n",
    "tweetDf['row_id'] = 0\n",
    "tweetDf = tweetDf[['row_id', 'tweet']]\n",
    "for row in tweetDf.iterrows():\n",
    "    index = row[0]\n",
    "    newVal = int(index) + 1\n",
    "    tweetDf['row_id'][index] = newVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542ecf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentDf = pd.DataFrame()\n",
    "sentimentDf['row_id'] = ['99999999999']\n",
    "sentimentDf['sentiment_type'] = 'NA999NA'\n",
    "sentimentDf['sentiment_score'] = 0\n",
    "\n",
    "print('Processing sentiment analysis...')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "tempDf = sentimentDf\n",
    "for index, row in tweetDf.iterrows():\n",
    "    scores = sia.polarity_scores(row[1])\n",
    "    for key, value in scores.items():\n",
    "        temp = [key,value,row[0]]\n",
    "        sentimentDf['row_id'] = row[0]\n",
    "        sentimentDf['sentiment_type'] = key\n",
    "        sentimentDf['sentiment_score'] = value\n",
    "        tempDf = tempDf.append(sentimentDf)\n",
    "#remove dummy row with row_id = 99999999999\n",
    "tempDf_cleaned = tempDf[tempDf.row_id != '99999999999']\n",
    "#remove duplicates if any exist\n",
    "tempDf_cleaned = tempDf_cleaned.drop_duplicates()\n",
    "# only keep rows where sentiment_type = compound\n",
    "tempDf_cleaned = tempDf[tempDf.sentiment_type == 'compound']\n",
    "\n",
    "print(tempDf_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98727749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55a295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
